{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCY6UbkkI9_N"
   },
   "source": [
    "# Style Transfer\n",
    "\n",
    "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
    "\n",
    "La idea de este trabajo final es reproducir el siguiente paper:\n",
    "\n",
    "https://arxiv.org/pdf/1508.06576.pdf\n",
    "\n",
    "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
    "\n",
    "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
    "\n",
    "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
    "\n",
    "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
    "\n",
    "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
    "\n",
    "A este procedimiento se lo denomina neural style transfer.\n",
    "\n",
    "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
    "\n",
    "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
    "\n",
    "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagen para estilo\n",
    "!curl -k -o estilo.jpg https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
    "\n",
    "# Imagen para contenido\n",
    "!curl -k -o contenido.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
    "\n",
    "# Creamos el directorio para los archivos de salida\n",
    "!mkdir /content/output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "id": "NIxH20o2eFoc",
    "outputId": "4785bcbb-4070-4e68-c2b5-4a1dfdccbad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WonderBrands\\miniconda3\\envs\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\WonderBrands\\AppData\\Local\\Temp\\ipykernel_12916\\2372166154.py:11: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "\n",
    "base_image_path = Path(\"C:\\\\Users\\\\WonderBrands\\\\Desktop\\\\ITBA\\\\TP final\\\\contenido.jpg\")\n",
    "style_reference_image_path = Path(\"C:\\\\Users\\\\WonderBrands\\\\Desktop\\\\ITBA\\\\TP final\\\\estilo.jpg\")\n",
    "result_prefix = Path(\"C:\\\\Users\\\\WonderBrands\\\\Desktop\\\\ITBA\\\\TP final\\\\output\")\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iLkV1bnFl_tK"
   },
   "outputs": [],
   "source": [
    "# Para el ejercicio 9\n",
    "\n",
    "base_image_path = Path(\"C:\\\\Users\\\\WonderBrands\\\\Desktop\\\\ITBA\\\\TP final\\\\contenido_ejercicio_9.jpg\")\n",
    "style_reference_image_path = Path(\"C:\\\\Users\\\\WonderBrands\\\\Desktop\\\\ITBA\\\\TP final\\\\estilo_ejercicio_9.jpg\")\n",
    "result_prefix = Path(\"C:\\\\Users\\\\WonderBrands\\\\Desktop\\\\ITBA\\\\TP final\\\\output\")\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz2PeGfpeYzj"
   },
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
    "\n",
    "Respuesta:\n",
    "Dichos parámetros se utilizan para ponderar las diferentes componentes de la función de pérdida durante la optimización de la imagen generada:\n",
    "\n",
    "- total_variation_weight, se utiliza para la regularización de la variación total en la imagen generada. Ayuda a mantener la imagen generada suave y continua, reduciendo el ruido y las anomalías. Un valor más alto dará como resultado una imagen más suave ya que penalizará las transiciones abruptas entre píxeles en la imagen generada.\n",
    "\n",
    "- style_weight, controla cuánto se prioriza la correspondencia del estilo de la imagen generada con el de la imagen de estilo. Un valor más alto dará como resultado una imagen que se asemeja más estrechamente al estilo de la imagen de estilo.\n",
    "\n",
    "- content_weight, controla cuánto se prioriza la correspondencia del contenido de la imagen generada con el de la imagen de contenido. Un valor más alto dará como resultado una imagen que conserva más fuertemente el contenido de la imagen de contenido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P9Dt3aaEmJWS"
   },
   "outputs": [],
   "source": [
    "total_variation_weight = 0.1\n",
    "style_weight = 10\n",
    "content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CQQJOhCVuse6"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las imágenes a utilizar\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg2ct-8agm1E"
   },
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "\n",
    "Ayuda: https://keras.io/applications/\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "La función realiza una serie de transformaciones en la imagen para prepararla para ser procesada por la red neuronal VGG19:\n",
    "\n",
    "- \"load_img\" carga la imagen del image_path dado y la redimensiona al tamaño objetivo (img_nrows x img_ncols).\n",
    "\n",
    "- \"img_to_array\" convierte la imagen cargada en un array NumPy. Esto es necesario porque las redes neuronales no pueden trabajar directamente con imágenes, necesitan arrays numéricos.\n",
    "\n",
    "- \"expand_dims\" agrega una dimensión extra al principio del array de la imagen. Esto se hace porque los modelos de redes neuronales convolucionales esperan un batch de imágenes como entrada, incluso si es un solo ejemplo, por lo que se agrega la dimensión del batch.\n",
    "\n",
    "- \"preprocess_input\" realiza un preprocesamiento específico para la red VGG19. La función convierte las imágenes de RGB a BGR, luego centra en cero cada canal de color con respecto al conjunto de datos de ImageNet, sin escalar. Esto es necesario porque la red VGG19 fue entrenada en el conjunto de datos de ImageNet, que utiliza este tipo de preprocesamiento.\n",
    "\n",
    "Por lo tanto, estas dos últimas líneas son necesarias para asegurar que la imagen de entrada esté en el formato correcto y tenga las características correctas para ser procesada por la red VGG19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tAkljg4zuzYd"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTf0YDSagt10"
   },
   "source": [
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "La función deprocess_image realiza el proceso inverso al de la función preprocess_image. Convierte una imagen procesada por la red VGG19 de nuevo a su formato original para que pueda ser visualizada correctamente.\n",
    "\n",
    "- \"x.reshape\" se utiliza para reorganizar el array x con el fin de tener las dimensiones correctas para una imagen RGB con tamaño (img_nrows, img_ncols).\n",
    "\n",
    "- Luego se deshace la normalización realizada en el preprocesamiento:\n",
    "\n",
    "- En tercer lugar se convierte la representación de color de 'BGR' (Blue, Green, Red) a 'RGB' (Red, Green, Blue) invirtiendo el orden de los canales de color\n",
    "\n",
    "- Por ultimo se asegura que los valores de píxeles estén en el rango válido [0, 255] y los convierte a tipo de dato 'uint8' (entero sin signo de 8 bits):\n",
    "\n",
    "La relación con el código anterior (\"preprocess_image\") es que \"deprocess_image\" se utiliza para revertir el preprocesamiento de las imágenes que han sido generadas o manipuladas por el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "y5LaTrsAu14z"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HYNio09mu4S3"
   },
   "outputs": [],
   "source": [
    "# get tensor representations of our images\n",
    "# K.variable convierte un numpy array en un tensor, para \n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "a1Lbw02Uu--o",
    "outputId": "6cc926fa-55af-43fa-fe91-3b68c0910502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WonderBrands\\miniconda3\\envs\\env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJEi0YI3Uzrm"
   },
   "source": [
    "Aclaración:\n",
    "\n",
    "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gGO_jGFfvEbF"
   },
   "outputs": [],
   "source": [
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "tdG59VRavHGB",
    "outputId": "a133befb-68d1-4c51-99e6-417c1103f726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WonderBrands\\miniconda3\\envs\\env\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# build the VGG19 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70-vs_jZkKVc"
   },
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
    "\n",
    "La matriz de Gram se define en términos de los mapas de características de una capa de la red. Es decir, dada una matriz de características de una capa convolucional, la matriz de Gram se calcula como el producto punto de las distintas filas de la matriz de caracteristicas. La idea detrás de la matriz de Gram es capturar las correlaciones estadísticas entre las distintas características de la capa. \n",
    "\n",
    "En el contexto de la transferencia de estilo, la matriz de Gram se utiliza para cuantificar el estilo de una imagen. Al comparar las matrices de Gram de la imagen de estilo de referencia y la imagen generada, se puede evaluar cómo de cerca la imagen generada se asemeja al estilo de la imagen de referencia.\n",
    "\n",
    "El proceso general de transferencia de estilo implica minimizar las diferencias entre las matrices de Gram de las capas de estilo de la imagen de referencia y la imagen generada, mientras se mantiene la estructura visual de la imagen de contenido. Esto se logra ajustando los pesos en la función de pérdida durante el proceso de optimización. Siendo que la función de pérdida de estilo se calcula comparando las matrices de Gram de la imagen generada y de la imagen de estilo.\n",
    "\n",
    "- ¿Por qué se permutan las dimensiones de x?\n",
    "\n",
    "La matriz de Gram se calcula a partir de los mapas de características de la imagen de entrada. La función \"K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\" aplana los mapas de características y los reorganiza para que puedan calcularse correctamente las correlaciones entre las características. \n",
    "\n",
    "Se hace para reorganizar los datos de entrada de manera que se puedan calcular correctamente las características de la matriz de Gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K1FODPATvJ1k"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBQkKFY0Rbx-"
   },
   "source": [
    "# 5) Losses:\n",
    "\n",
    "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "Rta:\n",
    "\n",
    "- style_loss: mide la diferencia de estilo entre la imagen de estilo y la imagen generada. Utiliza la matriz de Gram de ambas imágenes y calcula la suma de las diferencias cuadradas entre estas matrices. La pérdida de estilo intenta minimizar esta diferencia, lo que significa que intenta hacer que la imagen generada tenga un estilo similar al de la imagen de estilo.\n",
    "\n",
    "- content_loss: mide la diferencia de contenido entre la imagen base (la imagen a la que se le quiere transferir el estilo) y la imagen generada. Calcula la suma de las diferencias cuadradas entre estas dos imágenes. La pérdida de contenido intenta minimizar esta diferencia, lo que significa que intenta hacer que la imagen generada tenga un contenido similar al de la imagen base.\n",
    "\n",
    "- total_variation_loss: se utiliza para suavizar la imagen generada. Calcula la suma de las diferencias cuadradas entre los píxeles adyacentes en la imagen generada. Esta pérdida intenta minimizar estas diferencias, lo que significa que intenta hacer que la imagen generada sea más suave y menos ruidosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1-Gt0ahWvN6q"
   },
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XCqnju5RvQCo"
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "udEp5h31vRnY"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-65vcinbvTZ0"
   },
   "outputs": [],
   "source": [
    "# Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "pbz4n1OhvV2K",
    "outputId": "c2b208c6-7ddd-4a40-eeda-525f0809b963"
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JbydbOaVcvU"
   },
   "source": [
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "Celda 1: Define una función eval_loss_and_grads que toma una imagen (en forma de un array 1D), la remodela a su forma original, y luego calcula el valor de la pérdida y los gradientes para esa imagen utilizando la función f_outputs. Esta función es necesaria porque el optimizador que se utiliza más adelante necesita una forma de calcular tanto la pérdida como los gradientes para poder optimizar la imagen.\n",
    "\n",
    "Celda 2: Define una clase Evaluator que se utiliza para calcular y almacenar la pérdida y los gradientes. Esto se hace porque el optimizador fmin_l_bfgs_b requiere que la pérdida y los gradientes se calculen por separado, pero calcularlos por separado sería ineficiente. Por lo tanto, la clase Evaluator calcula tanto la pérdida como los gradientes en un solo paso y luego los almacena para su uso posterior.\n",
    "\n",
    "Celda 3: Crea una instancia de la clase Evaluator y luego utiliza el optimizador fmin_l_bfgs_b para minimizar la pérdida de estilo neuronal. Esto se hace iterativamente, y después de cada iteración, la imagen generada se guarda.\n",
    "\n",
    "La función fmin_l_bfgs_b es una implementación del algoritmo L-BFGS-B que se utiliza para minimizar una función. En este caso, la función que se minimiza es la pérdida de estilo neuronal. La función fmin_l_bfgs_b toma como entrada una función de pérdida, una imagen inicial, y una función que calcula los gradientes.\n",
    "\n",
    "La implementación del paper utiliza la red VGG-19, una red neuronal convolucional pre-entrenada, para extraer las representaciones de contenido y estilo de las imágenes.\n",
    "\n",
    "Optimización: El paper no especifica qué algoritmo de optimización se utiliza para minimizar la función de pérdida. Aca se utiliza el algoritmo L-BFGS-B para minimizar la función de pérdida.\n",
    "Normalización: En el paper, no se menciona ninguna normalización específica de las imágenes. Aca las imágenes se normalizan antes de ser procesadas por la red.\n",
    "Iteraciones: En el paper, no se especifica el número de iteraciones utilizadas para la optimización. Aca se realiza un número fijo de iteraciones para la optimización.\n",
    "\n",
    "En cuanto a las alternativas a fmin_l_bfgs_b, existen otros algoritmos de optimización que podrían utilizarse, como el descenso de gradiente estocástico (SGD), Adam, o RMSprop. Sin embargo, fmin_l_bfgs_b es un buen optimizador para este tipo de problemas debido a su eficiencia y precisión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Qbl9roIgvdb1"
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb0yOEl-WOE6"
   },
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n31YBwCVvhAI",
    "outputId": "4c1bf03c-9d66-48ea-93f2-4489fc20beaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 57918580000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_0.png\n",
      "Iteration 0 completed in 110s\n",
      "Start of iteration 1\n",
      "Current loss value: 23124046000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_1.png\n",
      "Iteration 1 completed in 115s\n",
      "Start of iteration 2\n",
      "Current loss value: 15553452000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_2.png\n",
      "Iteration 2 completed in 134s\n",
      "Start of iteration 3\n",
      "Current loss value: 11679978000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_3.png\n",
      "Iteration 3 completed in 127s\n",
      "Start of iteration 4\n",
      "Current loss value: 9535989000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_4.png\n",
      "Iteration 4 completed in 120s\n",
      "Start of iteration 5\n",
      "Current loss value: 8433246700.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_5.png\n",
      "Iteration 5 completed in 125s\n",
      "Start of iteration 6\n",
      "Current loss value: 7713597000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_6.png\n",
      "Iteration 6 completed in 118s\n",
      "Start of iteration 7\n",
      "Current loss value: 7089057300.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_7.png\n",
      "Iteration 7 completed in 119s\n",
      "Start of iteration 8\n",
      "Current loss value: 6578774500.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_8.png\n",
      "Iteration 8 completed in 122s\n",
      "Start of iteration 9\n",
      "Current loss value: 6225877000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_9.png\n",
      "Iteration 9 completed in 121s\n",
      "Start of iteration 10\n",
      "Current loss value: 5972686300.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_10.png\n",
      "Iteration 10 completed in 119s\n",
      "Start of iteration 11\n",
      "Current loss value: 5721667000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_11.png\n",
      "Iteration 11 completed in 119s\n",
      "Start of iteration 12\n",
      "Current loss value: 5517877000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_12.png\n",
      "Iteration 12 completed in 117s\n",
      "Start of iteration 13\n",
      "Current loss value: 5347825700.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_13.png\n",
      "Iteration 13 completed in 115s\n",
      "Start of iteration 14\n",
      "Current loss value: 5165589500.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_14.png\n",
      "Iteration 14 completed in 115s\n",
      "Start of iteration 15\n",
      "Current loss value: 5033625600.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_15.png\n",
      "Iteration 15 completed in 114s\n",
      "Start of iteration 16\n",
      "Current loss value: 4921907700.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_16.png\n",
      "Iteration 16 completed in 114s\n",
      "Start of iteration 17\n",
      "Current loss value: 4824804000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_17.png\n",
      "Iteration 17 completed in 114s\n",
      "Start of iteration 18\n",
      "Current loss value: 4699824600.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_18.png\n",
      "Iteration 18 completed in 114s\n",
      "Start of iteration 19\n",
      "Current loss value: 4618838500.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_19.png\n",
      "Iteration 19 completed in 113s\n",
      "Start of iteration 20\n",
      "Current loss value: 4523684400.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_20.png\n",
      "Iteration 20 completed in 113s\n",
      "Start of iteration 21\n",
      "Current loss value: 4454180400.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_21.png\n",
      "Iteration 21 completed in 114s\n",
      "Start of iteration 22\n",
      "Current loss value: 4401743000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_22.png\n",
      "Iteration 22 completed in 114s\n",
      "Start of iteration 23\n",
      "Current loss value: 4321541600.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_23.png\n",
      "Iteration 23 completed in 113s\n",
      "Start of iteration 24\n",
      "Current loss value: 4265374700.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_24.png\n",
      "Iteration 24 completed in 113s\n",
      "Start of iteration 25\n",
      "Current loss value: 4200327700.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_25.png\n",
      "Iteration 25 completed in 114s\n",
      "Start of iteration 26\n",
      "Current loss value: 4146592300.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_26.png\n",
      "Iteration 26 completed in 113s\n",
      "Start of iteration 27\n",
      "Current loss value: 4094826000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_27.png\n",
      "Iteration 27 completed in 114s\n",
      "Start of iteration 28\n",
      "Current loss value: 4051619300.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_28.png\n",
      "Iteration 28 completed in 113s\n",
      "Start of iteration 29\n",
      "Current loss value: 4010358000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_29.png\n",
      "Iteration 29 completed in 115s\n",
      "Start of iteration 30\n",
      "Current loss value: 3971500300.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_30.png\n",
      "Iteration 30 completed in 113s\n",
      "Start of iteration 31\n",
      "Current loss value: 3935116800.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_31.png\n",
      "Iteration 31 completed in 113s\n",
      "Start of iteration 32\n",
      "Current loss value: 3900308000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_32.png\n",
      "Iteration 32 completed in 113s\n",
      "Start of iteration 33\n",
      "Current loss value: 3868170200.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_33.png\n",
      "Iteration 33 completed in 115s\n",
      "Start of iteration 34\n",
      "Current loss value: 3840392200.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_34.png\n",
      "Iteration 34 completed in 117s\n",
      "Start of iteration 35\n",
      "Current loss value: 3804486100.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_35.png\n",
      "Iteration 35 completed in 114s\n",
      "Start of iteration 36\n",
      "Current loss value: 3776603000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_36.png\n",
      "Iteration 36 completed in 114s\n",
      "Start of iteration 37\n",
      "Current loss value: 3742747100.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_37.png\n",
      "Iteration 37 completed in 115s\n",
      "Start of iteration 38\n",
      "Current loss value: 3709512700.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_38.png\n",
      "Iteration 38 completed in 207s\n",
      "Start of iteration 39\n",
      "Current loss value: 3680211500.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_39.png\n",
      "Iteration 39 completed in 797s\n",
      "Start of iteration 40\n",
      "Current loss value: 3657989000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_40.png\n",
      "Iteration 40 completed in 782s\n",
      "Start of iteration 41\n",
      "Current loss value: 3636680400.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_41.png\n",
      "Iteration 41 completed in 798s\n",
      "Start of iteration 42\n",
      "Current loss value: 3615157800.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_42.png\n",
      "Iteration 42 completed in 278s\n",
      "Start of iteration 43\n",
      "Current loss value: 3594121200.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_43.png\n",
      "Iteration 43 completed in 113s\n",
      "Start of iteration 44\n",
      "Current loss value: 3573440000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_44.png\n",
      "Iteration 44 completed in 119s\n",
      "Start of iteration 45\n",
      "Current loss value: 3554186200.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_45.png\n",
      "Iteration 45 completed in 123s\n",
      "Start of iteration 46\n",
      "Current loss value: 3531987000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_46.png\n",
      "Iteration 46 completed in 122s\n",
      "Start of iteration 47\n",
      "Current loss value: 3511333600.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_47.png\n",
      "Iteration 47 completed in 118s\n",
      "Start of iteration 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 3494675000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_48.png\n",
      "Iteration 48 completed in 120s\n",
      "Start of iteration 49\n",
      "Current loss value: 3479739000.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_49.png\n",
      "Iteration 49 completed in 123s\n",
      "Start of iteration 50\n",
      "Current loss value: 3466101800.0\n",
      "Image saved as C:\\Users\\WonderBrands\\Desktop\\ITBA\\TP final\\output\\Ejercicio_9_50.png\n",
      "Iteration 50 completed in 117s\n",
      "Start of iteration 51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12916\\4032981720.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start of iteration'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n\u001b[0m\u001b[0;32m     11\u001b[0m                                      fprime=evaluator.grads, maxfun=20)\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current loss value:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m             'maxls': maxls}\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0m\u001b[0;32m    200\u001b[0m                            **opts)\n\u001b[0;32m    201\u001b[0m     d = {'grad': res['jac'],\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[1;31m# Make sure the function returns a true scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12916\\258067808.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_loss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12916\\2482384706.py\u001b[0m in \u001b[0;36meval_loss_and_grads\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_loss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_nrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_ncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\keras\\src\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4605\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4607\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4608\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4609\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1505\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1506\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('Ejercicio_9_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkiJtofbWWy1"
   },
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "Respuesta:\n",
    "Se realizaron tres combinaciones diferentes, para cada una se adjuntan 5 imagenes de titulo por ejemplo \"Ejercicio_8_1(total_variation_weight = 1, style_weight = 0.1, content_weight = 5)\". Es decir, se indica la combinacion y el numero de iteracion de la imagen. \n",
    "\n",
    "Primer combinación:\n",
    "- total_variation_weight = 1\n",
    "- style_weight = 0.1\n",
    "- content_weight = 5 \n",
    "\n",
    "Con esta configuración, la imagen generada se parecerá más a la imagen de contenido original.\n",
    "\n",
    "Segunda combinación:\n",
    "- total_variation_weight = 1\n",
    "- style_weight = 1\n",
    "- content_weight = 0.5 \n",
    "\n",
    "Con esta configuración, la imagen generada adoptará más del estilo de la imagen de referencia.\n",
    "\n",
    "Tercera Combinación:\n",
    "- total_variation_weight = 5\n",
    "- style_weight = 0.1\n",
    "- content_weight = 1 \n",
    "\n",
    "Con esta configuración, la imagen generada será más suave y tendrá menos ruido.\n",
    "\n",
    "\n",
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "Para este ejercicio se debe reiniciar el kernel y correr la celda que carga las imagenes del ejercicio (se adjuntan las imagenes utilizadas para que se pueda reproducir el mismo), como tambien se adjuntan 50 iteraciones del ejercicio.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Trabajo Final CNN - Style Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
